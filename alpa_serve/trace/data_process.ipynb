{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "from typing import List, Dict\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon, gamma, pareto\n",
    "import numpy as np\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_azure_v1_trace(trace_dir, n_day=14):\n",
    "    if not os.path.exists(trace_dir):\n",
    "        raise RuntimeError(f\"{trace_dir}\")\n",
    "    tracelines = OrderedDict()\n",
    "    print(f\"Reading azure v1 trace in 14 days; it might take a while...\")\n",
    "    tic = time.time()\n",
    "    for i in range(1, n_day + 1):\n",
    "        day_str = str(i) if i >= 10 else \"0\" + str(i)\n",
    "        filename = os.path.join(trace_dir, f\"invocations_per_function_md.anon.d{day_str}.csv\")\n",
    "        print(f\"Read file: {filename}\")\n",
    "        with open(filename, newline=\"\") as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                function_name = row[\"HashFunction\"]\n",
    "                histogram_1min = np.array([int(row[str(j)]) for j in range(1, 1441)], dtype=np.int32)\n",
    "                if i == 1:\n",
    "                    assert function_name not in tracelines\n",
    "                    tracelines[function_name] = histogram_1min\n",
    "                else:\n",
    "                    expected_size = 1440 * (i - 1)\n",
    "                    if function_name in tracelines:\n",
    "                        cur_size = tracelines[function_name].size\n",
    "                        if cur_size != expected_size:\n",
    "                            diff = expected_size - cur_size\n",
    "                            assert diff % 1440 == 0\n",
    "                            tracelines[function_name] = np.concatenate((tracelines[function_name],\n",
    "                                                                       np.zeros((diff,), dtype=np.int32),\n",
    "                                                                       histogram_1min))\n",
    "                        else:\n",
    "                            tracelines[function_name] = np.concatenate((tracelines[function_name],\n",
    "                                                                       histogram_1min))\n",
    "                    else:\n",
    "                        tracelines[function_name] = np.concatenate((np.zeros((expected_size, ), dtype=np.int32),\n",
    "                                                                   histogram_1min))\n",
    "    for function_name, histogram_1min in tracelines.items():\n",
    "        if histogram_1min.size != n_day * 1440:\n",
    "            diff = n_day * 1440 - histogram_1min.size\n",
    "            assert diff % 1440 == 0\n",
    "            tracelines[function_name] = np.concatenate((tracelines[function_name], np.zeros((diff,), dtype=np.int32)))\n",
    "    print(f\"Reading takes: {time.time() - tic}s.\")\n",
    "\n",
    "    # report the stats.\n",
    "    num_function_invocations = []\n",
    "    for function_name, histogram_1min in tracelines.items():\n",
    "        assert (histogram_1min.size == 1440 * n_day), f\"length: {histogram_1min.size}\"\n",
    "        num_function_invocations.append(np.sum(histogram_1min))\n",
    "    num_functions = len(tracelines.keys())\n",
    "    print(f\"Azure trace v1, stats: #days: {n_day}, #functions: {num_functions}, \"\n",
    "          f\"total invocations: {sum(num_function_invocations)}, \"\n",
    "          f\"max: {max(num_function_invocations)}, min: {min(num_function_invocations)}, \"\n",
    "          f\"avg: {np.mean(num_function_invocations):.2f}\")\n",
    "\n",
    "    # pickle it to disk\n",
    "    save_path = os.path.join(trace_dir, \"azure_v1.pkl\")\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        pickle.dump(tracelines, handle)\n",
    "    print(f\"Dump the data into {save_path}, file size: {os.path.getsize(save_path) // 1e6} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading azure v1 trace in 14 days; it might take a while...\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d01.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d02.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d03.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d04.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d05.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d06.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d07.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d08.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d09.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d10.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d11.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d12.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d13.csv\n",
      "Read file: /home/zy/data/datasets/azurefunctions-dataset2019/invocations_per_function_md.anon.d14.csv\n",
      "Reading takes: 418.4372704029083s.\n",
      "Azure trace v1, stats: #days: 14, #functions: 72359, total invocations: 12495810846, max: 1683728143, min: 1, avg: 172691.87\n",
      "Dump the data into /home/zy/data/datasets/azurefunctions-dataset2019/azure_v1.pkl, file size: 5842.0 MB.\n"
     ]
    }
   ],
   "source": [
    "preprocess_azure_v1_trace('/home/zy/data/datasets/azurefunctions-dataset2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_azure_v2_trace(trace_dir):\n",
    "    \"\"\"Load and process azure v2 trace.\"\"\"\n",
    "    if not os.path.exists(trace_dir):\n",
    "        raise RuntimeError(f\"{trace_dir}\")\n",
    "    filename = os.path.join(trace_dir, \"AzureFunctionsInvocationTraceForTwoWeeksJan2021.txt\")\n",
    "    tracelines = OrderedDict()\n",
    "    print(f\"Reading azure v2 trace in 14 days...\")\n",
    "    tic = time.time()\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            function_name = row[\"func\"]\n",
    "            end_time = float(row[\"end_timestamp\"])\n",
    "            duration = float(row[\"duration\"])\n",
    "            if function_name not in tracelines:\n",
    "                tracelines[function_name] = [end_time - duration]\n",
    "            else:\n",
    "                tracelines[function_name].append(end_time -duration)\n",
    "\n",
    "    for function_name, trace in tracelines.items():\n",
    "        tracelines[function_name] = np.sort(np.array(tracelines[function_name]))\n",
    "    print(f\"Reading takes: {time.time() - tic}s.\")\n",
    "    # Do some check and report stats:\n",
    "    num_functions = len(tracelines.keys())\n",
    "    num_function_invocations = []\n",
    "    for function_name, trace in tracelines.items():\n",
    "        num_function_invocations.append(len(trace))\n",
    "    print(f\"Azure trace v2, stats: #days: 14, #functions: {num_functions}, \"\n",
    "          f\"total invocations: {sum(num_function_invocations)}, \"\n",
    "          f\"max: {max(num_function_invocations)}, min: {min(num_function_invocations)}, \"\n",
    "          f\"avg: {np.mean(num_function_invocations):.2f}\")\n",
    "\n",
    "    # pickle it to disk\n",
    "    save_path = os.path.join(trace_dir, \"azure_v2.pkl\")\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        pickle.dump(tracelines, handle)\n",
    "    print(f\"Dump the data into {save_path}, file size: {os.path.getsize(save_path) // 1e6} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading azure v2 trace in 14 days...\n",
      "Reading takes: 8.449933052062988s.\n",
      "Azure trace v2, stats: #days: 14, #functions: 424, total invocations: 1980951, max: 535667, min: 1, avg: 4672.05\n",
      "Dump the data into /home/zy/data/datasets/azure_v2.pkl, file size: 15.0 MB.\n"
     ]
    }
   ],
   "source": [
    "preprocess_azure_v2_trace('/home/zy/data/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
